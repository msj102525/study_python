
[Episode  20, Steps 19,543] Episode Reward:  -210.814, Policy Loss:  -1.259, Training Steps:    20 Elapsed Time: 00:00:03
[Episode  40, Steps 38,962] Episode Reward:  -323.593, Policy Loss:  -8.929, Training Steps:    40 Elapsed Time: 00:00:07
[Episode  60, Steps 58,489] Episode Reward:  -318.131, Policy Loss: -10.067, Training Steps:    60 Elapsed Time: 00:00:11
[Episode  80, Steps 77,162] Episode Reward:  -321.717, Policy Loss:  -8.004, Training Steps:    80 Elapsed Time: 00:00:14
[Episode 100, Steps 96,472] Episode Reward:  -328.344, Policy Loss:  -9.548, Training Steps:   100 Elapsed Time: 00:00:18
[Validation Episode Reward: [-11.09838471 -10.71106388 -10.64880961]] Average: -10.819
[Episode 120, Steps 114,408] Episode Reward:  -326.598, Policy Loss:  -9.624, Training Steps:   120 Elapsed Time: 00:00:22
[Episode 140, Steps 133,877] Episode Reward:  -324.358, Policy Loss:  -9.521, Training Steps:   140 Elapsed Time: 00:00:26
[Episode 160, Steps 153,541] Episode Reward:  -326.821, Policy Loss:  -9.588, Training Steps:   160 Elapsed Time: 00:00:30
[Episode 180, Steps 171,164] Episode Reward:   -69.328, Policy Loss:  -2.587, Training Steps:   180 Elapsed Time: 00:00:33
[Episode 200, Steps 190,383] Episode Reward:  -328.157, Policy Loss:  -8.389, Training Steps:   200 Elapsed Time: 00:00:37
[Validation Episode Reward: [-178.55676099 -185.64226203 -181.03773497]] Average: -181.746
[Episode 220, Steps 209,005] Episode Reward:  -191.298, Policy Loss:  -1.514, Training Steps:   220 Elapsed Time: 00:00:41
[Episode 240, Steps 226,790] Episode Reward:  -215.353, Policy Loss:  -3.075, Training Steps:   240 Elapsed Time: 00:00:45
[Episode 260, Steps 243,746] Episode Reward:   -76.224, Policy Loss:  -0.015, Training Steps:   260 Elapsed Time: 00:00:48
[Episode 280, Steps 262,306] Episode Reward:  -323.929, Policy Loss:  -8.237, Training Steps:   280 Elapsed Time: 00:00:52
[Episode 300, Steps 280,031] Episode Reward:  -320.728, Policy Loss:  -4.798, Training Steps:   300 Elapsed Time: 00:00:55
[Validation Episode Reward: [-255.06108117 -253.07644494 -255.9994438 ]] Average: -254.712
[Episode 320, Steps 297,392] Episode Reward:  -321.343, Policy Loss: -10.543, Training Steps:   320 Elapsed Time: 00:00:59
[Episode 340, Steps 316,181] Episode Reward:  -323.572, Policy Loss:  -7.849, Training Steps:   340 Elapsed Time: 00:01:03
[Episode 360, Steps 334,945] Episode Reward:  -186.933, Policy Loss:   2.179, Training Steps:   360 Elapsed Time: 00:01:07
[Episode 380, Steps 352,290] Episode Reward:  -327.647, Policy Loss:  -8.207, Training Steps:   380 Elapsed Time: 00:01:10
[Episode 400, Steps 370,900] Episode Reward:  -317.667, Policy Loss: -11.404, Training Steps:   400 Elapsed Time: 00:01:14
[Validation Episode Reward: [-294.83617091 -299.90354465 -303.69039102]] Average: -299.477
[Episode 420, Steps 388,852] Episode Reward:  -318.003, Policy Loss:  -8.953, Training Steps:   420 Elapsed Time: 00:01:17
[Episode 440, Steps 407,674] Episode Reward:  -325.218, Policy Loss: -10.527, Training Steps:   440 Elapsed Time: 00:01:21
[Episode 460, Steps 426,712] Episode Reward:  -318.825, Policy Loss: -14.564, Training Steps:   460 Elapsed Time: 00:01:25
[Episode 480, Steps 444,025] Episode Reward:  -321.068, Policy Loss: -13.333, Training Steps:   480 Elapsed Time: 00:01:29
[Episode 500, Steps 462,064] Episode Reward:  -330.407, Policy Loss: -13.846, Training Steps:   500 Elapsed Time: 00:01:32
[Validation Episode Reward: [-318.00104826 -303.09070952 -318.34312929]] Average: -313.145
[Episode 520, Steps 480,340] Episode Reward:  -325.578, Policy Loss: -15.335, Training Steps:   520 Elapsed Time: 00:01:36
[Episode 540, Steps 497,957] Episode Reward:  -323.987, Policy Loss: -11.343, Training Steps:   540 Elapsed Time: 00:01:39
[Episode 560, Steps 515,325] Episode Reward:  -127.949, Policy Loss:  -1.365, Training Steps:   560 Elapsed Time: 00:01:43
[Episode 580, Steps 533,948] Episode Reward:  -102.424, Policy Loss:  -0.845, Training Steps:   580 Elapsed Time: 00:01:47
[Episode 600, Steps 550,789] Episode Reward:  -317.038, Policy Loss:  -9.281, Training Steps:   600 Elapsed Time: 00:01:50
[Validation Episode Reward: [-325.06148737 -307.91744008 -327.37529592]] Average: -320.118
[Episode 620, Steps 568,504] Episode Reward:  -171.462, Policy Loss:  -4.391, Training Steps:   620 Elapsed Time: 00:01:53
[Episode 640, Steps 586,897] Episode Reward:  -324.019, Policy Loss: -14.850, Training Steps:   640 Elapsed Time: 00:01:57
[Episode 660, Steps 605,170] Episode Reward:  -162.917, Policy Loss:   0.262, Training Steps:   660 Elapsed Time: 00:02:01
[Episode 680, Steps 623,956] Episode Reward:  -319.603, Policy Loss: -15.672, Training Steps:   680 Elapsed Time: 00:02:05
[Episode 700, Steps 641,247] Episode Reward:   -63.977, Policy Loss:  -2.859, Training Steps:   700 Elapsed Time: 00:02:08
[Validation Episode Reward: [-319.51538207 -282.39090068 -313.14658163]] Average: -305.018
[Episode 720, Steps 657,472] Episode Reward:  -321.439, Policy Loss: -12.120, Training Steps:   720 Elapsed Time: 00:02:11
[Episode 740, Steps 674,700] Episode Reward:  -320.316, Policy Loss: -17.138, Training Steps:   740 Elapsed Time: 00:02:15
[Episode 760, Steps 693,630] Episode Reward:  -319.432, Policy Loss: -13.405, Training Steps:   760 Elapsed Time: 00:02:18
[Episode 780, Steps 711,857] Episode Reward:  -161.562, Policy Loss:   2.616, Training Steps:   780 Elapsed Time: 00:02:22
[Episode 800, Steps 728,142] Episode Reward:  -322.929, Policy Loss: -12.256, Training Steps:   800 Elapsed Time: 00:02:25
[Validation Episode Reward: [-336.6515898  -314.13530324 -348.5116822 ]] Average: -333.100
[Episode 820, Steps 746,511] Episode Reward:  -320.964, Policy Loss: -15.482, Training Steps:   820 Elapsed Time: 00:02:29
[Episode 840, Steps 763,176] Episode Reward:  -317.200, Policy Loss: -12.749, Training Steps:   840 Elapsed Time: 00:02:32
[Episode 860, Steps 780,429] Episode Reward:   -69.719, Policy Loss:   2.485, Training Steps:   860 Elapsed Time: 00:02:36
[Episode 880, Steps 800,046] Episode Reward:  -319.517, Policy Loss: -13.907, Training Steps:   880 Elapsed Time: 00:02:39
[Episode 900, Steps 818,277] Episode Reward:  -118.295, Policy Loss:   1.668, Training Steps:   900 Elapsed Time: 00:02:43
[Validation Episode Reward: [-298.45648718 -292.91568122 -319.37304055]] Average: -303.582
[Episode 920, Steps 834,795] Episode Reward:   -25.465, Policy Loss:   0.279, Training Steps:   920 Elapsed Time: 00:02:47
[Episode 940, Steps 851,231] Episode Reward:  -168.271, Policy Loss:   3.922, Training Steps:   940 Elapsed Time: 00:02:50
[Episode 960, Steps 867,073] Episode Reward:  -315.993, Policy Loss: -13.558, Training Steps:   960 Elapsed Time: 00:02:53
[Episode 980, Steps 883,943] Episode Reward:   -53.730, Policy Loss:  -1.263, Training Steps:   980 Elapsed Time: 00:02:56
Traceback (most recent call last):
  File "D:\python\study_python\_03_DQN\e_reinforce_test\d_reinforce_train.py", line 269, in <module>
    main()
  File "D:\python\study_python\_03_DQN\e_reinforce_test\d_reinforce_train.py", line 265, in main
    reinforce.train_loop()
  File "D:\python\study_python\_03_DQN\e_reinforce_test\d_reinforce_train.py", line 75, in train_loop
    action = self.policy.get_action(observation)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\python\study_python\_03_DQN\e_reinforce_test\c_policy_and_value.py", line 54, in get_action
    mu_v, std_v = self.forward(x)
                  ^^^^^^^^^^^^^^^
  File "D:\python\study_python\_03_DQN\e_reinforce_test\c_policy_and_value.py", line 39, in forward
    x = F.relu(self.fc1(x))
               ^^^^^^^^^^^
  File "D:\python\study_python\_03_DQN\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\python\study_python\_03_DQN\.venv\Lib\site-packages\torch\nn\modules\module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\python\study_python\_03_DQN\.venv\Lib\site-packages\torch\nn\modules\linear.py", line 116, in forward
    return F.linear(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt